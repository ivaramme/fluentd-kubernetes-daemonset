
# AUTOMATICALLY GENERATED
# DO NOT EDIT THIS FILE DIRECTLY, USE /templates/conf/fluent.conf.erb

@include "#{ENV['FLUENTD_SYSTEMD_CONF'] || 'systemd'}.conf"
@include "#{ENV['FLUENTD_PROMETHEUS_CONF'] || 'prometheus'}.conf"
@include kubernetes.conf
@include conf.d/*.conf

<match **>
  @type azure-loganalytics
  customer_id "#{ENV['CUSTOMER_ID']}"
  shared_key "#{ENV['KEY_STRING']}"
  log_type "#{ENV['EVENT_TYPE_NAME'] || 'ContainerLog'}"
  add_time_field true
  time_field_name mytime
  time_format %s
  localtime true
  add_tag_field false
  tag_field_name mytag
  <buffer>
    # Set the buffer type to file to improve the reliability and reduce the memory consumption
    @type file
    path /var/log/fluentd-buffers/azure-loganalytics.buffer
    # Set queue_full action to block because we want to pause gracefully
    # in case of the off-the-limits load instead of throwing an exception
    overflow_action block
    # Set the chunk limit conservatively to avoid exceeding the GCL limit
    # of 10MiB per write request.
    chunk_limit_size 2M
    # Cap the combined memory usage of this buffer and the one below to
    # 2MiB/chunk * (6 + 2) chunks = 16 MiB
    queue_limit_length 6
    # Never wait more than 5 seconds before flushing logs in the non-error case.
    flush_interval 30s
    # Never wait longer than 30 seconds between retries.
    retry_max_interval 30
    # Disable the limit on the number of retries (retry forever).
    retry_forever "#{ENV['RETRY_FOREVER'] || false}"
    retry_max_times 2 
    # Use multiple threads for processing.
    flush_thread_count "#{ENV['FLUSH_THREAD_COUNT'] || 2}"
    </buffer>
</match>

